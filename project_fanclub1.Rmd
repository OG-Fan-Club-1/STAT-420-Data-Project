---
title: "STAT 420: Final Data Project (OG Fan Club #1)"
authors: "Sarah Lee, Aayush Aggarwal, Albert Sadiku, Alexander Marcozzi"
date: "Due: Monday, December 14 by 11:30 PM CT"
output: 
  html_document: 
    theme: readable
    toc: yes
---

# Data Explaination and Setup

<br>

**Description of the Data:**

The data file used for this project focuses on pollution in the U.S. The file includes emission data from cities and towns around the country across multiple days and years, though we have chosen to focus on 2016 in the interest of workability. The variables include location information, such as state, city, and county, along with pollution information such as the amount of various greenhouse gasses emitted such as NO2, CO2, SO2, and O3. In total, there are 24 variables that actually contain data, and there are 6151 observations after cleaning duplicate entries and taking just the 2016 data. We will be attempting to create a model with CO.Mean as the response.

<br>

**Note about the data:**

The original dataset had two sets of duplicated measurements each day, the only difference being the CO measurements (the last 3 columns on the original data). The first set of duplicates had a value for ‘CO.AQI’ and the other duplicated set did not (marked as ‘NA’). To keep the data consistent, we removed the second duplicated set that had the 'NA' - ultimately cleaning the dataset so there's only one recorded data point was present per day. We will also remove certain unnecessary variables and entries that are missing data

<br>

**Import the data:**
```{r, message = FALSE, warning = FALSE}
#install.packages("lmtest")
library(faraway)  # for VIF function
library(MASS)     # for boxcox
library(lmtest)   # for shapiro normality test
pollution = read.csv('pollution_no_dup.csv')
pollution = subset(pollution, select = -c(X, State.Code, County.Code, Site.Num, Address, NO2.Units, O3.Units, SO2.Units, CO.Units))
pollution = pollution[complete.cases(pollution), ]  # remove entries that are missing data
names(pollution)
```

<br>

**Function Definitions:**
```{r}
plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  plot(fitted(model), resid(model), 
       col = pointcol, pch = 20, cex = 1.5,
       xlab = "Fitted", ylab = "Residuals")
  abline(h = 0, col = linecol, lwd = 2)
}

plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
  qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
  qqline(resid(model), col = linecol, lwd = 2)
}
```


# Building the Model

**Check for multicollinearity:**

```{r}
numeric_data = subset(pollution, select = -c(State, County, City, Date.Local))
numeric_data = numeric_data[is.finite(rowSums(log(numeric_data[-1]))),]
pollution_add = lm(CO.Mean ~ ., data = numeric_data)

vif(pollution_add)
names(numeric_data)[vif(pollution_add) <= 5]
names(numeric_data)[vif(pollution_add) <= 10]
```

<br>

We can see that quite a few of our prospective predictor variables have large VIF values, which suggests multicolinearity. Our next step will be to compare the resulting smaller models with the model containing all predictors.

<br>

```{r}

pollution_add_less5 = lm(CO.Mean ~ NO2.1st.Max.Hour + O3.1st.Max.Hour + SO2.Mean + SO2.1st.Max.Hour + CO.1st.Max.Value, data = numeric_data)

pollution_add_less10 = lm(CO.Mean ~ NO2.Mean + NO2.1st.Max.Hour + O3.Mean + O3.1st.Max.Hour + SO2.Mean + SO2.1st.Max.Hour + CO.1st.Max.Value + CO.1st.Max.Value + CO.AQI, data = numeric_data)

anova(pollution_add_less5, pollution_add_less10)
anova(pollution_add_less10, pollution_add)

summary(pollution_add_less5)$adj.r.squared
summary(pollution_add_less10)$adj.r.squared
summary(pollution_add)$adj.r.squared
```

<br>

From the ANOVA tests as well as the adjusted R-squared values above, it seems that the multicollinearity is not a problem, so we will not drop any predictors.

<br>

**Trying Two-way Interactions:**

<br>

Now that we have made a decision on multicollinearity, we will try models with two-way interactions.

<br>

```{r}
pollution_two_way = lm(CO.Mean ~ . ^ 2, data = numeric_data)

anova(pollution_add, pollution_two_way)

summary(pollution_two_way)$adj.r.squared
```

<br>

As we can see, the model using two-way interactions outperforms the previous best additive model. We can now try to use backwards AIC variable selection to make the model smaller.

<br>

```{r}
pollution_two_back_aic = step(pollution_two_way, direction = "backward", trace = 0)

anova(pollution_two_back_aic, pollution_two_way)

summary(pollution_two_way)$adj.r.squared
summary(pollution_two_back_aic)$adj.r.squared
```

<br>

From the ANOVA test as well as the adjusted R-squared values, we can see that the model produced from the backwards AIC variable selection performs better than the previous best model with all two-way interactions. This is good, as we have managed to significantly reduce the number of predictors, from $`r length(names(coef(pollution_two_way)))`$ to $`r length(names(coef(pollution_two_back_aic)))`$.

<br>

**Testing assumptions (work in progress):**
```{r}
# bptest(pollution_add)
# shapiro.test(resid(pollution_add))
# 
# plot_fitted_resid(pollution_add)
# 
# 
# 
# lambda = with(boxcox(pollution_add, plotit = FALSE), x[which.max(y)])
# lambda
# 
# pollution_add_2 = lm((((CO.Mean ^ lambda) - 1) / lambda) ~ ., data = numeric_data)
# plot_fitted_resid(pollution_add_2)
# summary(pollution_add_2)$adj.r.squared
# 
# bptest(pollution_add_2)
# shapiro.test(resid(pollution_add_2))
# 
# pollution_sqr = lm(CO.Mean ~ . ^ 2, data = numeric_data)
# plot_fitted_resid(pollution_sqr)
# anova(pollution_add, pollution_sqr)
```

<br>

**Trying Categorical Predictors:**

<br>

**Finishing Touches?**

<br>

**Summary and Conclusion**

<br>


